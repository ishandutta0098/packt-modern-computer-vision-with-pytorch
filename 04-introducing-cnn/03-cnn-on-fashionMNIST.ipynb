{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN on FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torch import optim\n",
    "from torch.optim import SGD, Adam\n",
    "from torchsummary import summary\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_directory = 'D:/book-implementations/packt-modern-computer-vision-with-pytorch/03-building-deep-nn-with-pytorch/images/FMNIST'\n",
    "\n",
    "fmnist = datasets.FashionMNIST(\n",
    "    data_directory,\n",
    "    download=False,\n",
    "    train=True\n",
    "    )\n",
    "\n",
    "tr_images = fmnist.data\n",
    "tr_targets = fmnist.targets \n",
    "\n",
    "val_fmnist = datasets.FashionMNIST(\n",
    "    data_directory,\n",
    "    download=False,\n",
    "    train=False\n",
    "    )\n",
    "\n",
    "val_images = val_fmnist.data \n",
    "val_targets = val_fmnist.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "class FMNISTDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        x = x.float()/255\n",
    "        x = x.view(-1,1,28,28)\n",
    "        self.x, self.y = x, y \n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        x, y = self.x[ix], self.y[ix]        \n",
    "        return x.to(device), y.to(device)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.x)\n",
    "\n",
    "# Model\n",
    "\n",
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=3),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 128, kernel_size=3),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(3200, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 10)\n",
    "    ).to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = Adam(\n",
    "        model.parameters(),\n",
    "        lr=1e-3\n",
    "    )\n",
    "\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Function\n",
    "\n",
    "def train_batch(x, y, model, opt, loss_fn):\n",
    "    prediction = model(x)\n",
    "    batch_loss = loss_fn(prediction, y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def accuracy(x, y, model):\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    max_values, argmaxes = prediction.max(-1)\n",
    "    is_correct = argmaxes == y\n",
    "    return is_correct.cpu().numpy().tolist()\n",
    "\n",
    "def get_data():     \n",
    "    train = FMNISTDataset(tr_images, tr_targets)     \n",
    "    trn_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    val = FMNISTDataset(val_images, val_targets)     \n",
    "    val_dl = DataLoader(val, batch_size=len(val_images), shuffle=True)\n",
    "    return trn_dl, val_dl\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_loss(x, y, model):\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    val_loss = loss_fn(prediction, y)\n",
    "    return val_loss.item()\n",
    "\n",
    "trn_dl, val_dl = get_data()\n",
    "model, loss_fn, optimizer = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "train_losses, train_accuracies = [], []\n",
    "val_losses, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    train_epoch_losses, train_epoch_accuracies = [], []\n",
    "\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "        train_epoch_losses.append(batch_loss)        \n",
    "    train_epoch_loss = np.array(train_epoch_losses).mean()\n",
    "\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        is_correct = accuracy(x, y, model)\n",
    "        train_epoch_accuracies.extend(is_correct)\n",
    "    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
    "\n",
    "    for ix, batch in enumerate(iter(val_dl)):\n",
    "        x, y = batch\n",
    "        val_is_correct = accuracy(x, y, model)\n",
    "        validation_loss = val_loss(x, y, model)\n",
    "    val_epoch_accuracy = np.mean(val_is_correct)\n",
    "\n",
    "    print(f\"Loss: {train_epoch_loss}    Accuracy: {train_epoch_accuracy}\")\n",
    "\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    train_accuracies.append(train_epoch_accuracy)\n",
    "    val_losses.append(validation_loss)\n",
    "    val_accuracies.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "epochs = np.arange(5)+1\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(epochs, train_losses, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
    "plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "plt.title('Training and validation loss with CNN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid('off')\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(epochs, train_accuracies, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')\n",
    "plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "plt.title('Training and validation accuracy with CNN')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]) \n",
    "plt.legend()\n",
    "plt.grid('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "ix = 24300\n",
    "\n",
    "for px in range(-5,6):\n",
    "  \n",
    "  img = tr_images[ix]/255.\n",
    "  img = img.view(28, 28)\n",
    "  img2 = np.roll(img, px, axis=1)\n",
    "  img3 = torch.Tensor(img2).view(-1,1,28,28).to(device)\n",
    "  np_output = model(img3).cpu().detach().numpy()\n",
    "  pred = np.exp(np_output)/np.sum(np.exp(np_output))\n",
    "  preds.append(pred)\n",
    "  plt.imshow(img2)\n",
    "  plt.title(fmnist.classes[pred[0].argmax()])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(12,10))\n",
    "plt.title('Probability of each class for various translations')\n",
    "sns.heatmap(\n",
    "    np.array(preds).reshape(11,10), \n",
    "    annot=True, \n",
    "    ax=ax, \n",
    "    fmt='.2f', \n",
    "    xticklabels=fmnist.classes, \n",
    "    yticklabels=[str(i)+str(' pixels') for i in range(-5,6)], \n",
    "    cmap='gray'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "323c9bce7ac1a9ea4994ab47268d44dc7215c46ff68d641ed6324f9037e8a8c4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
